{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ccb45a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Notebook 01: Data Description\n",
    "\n",
    "This notebook describes the dataset used in this project.  \n",
    "It addresses the following questions:\n",
    "\n",
    "1. What do the aggregated files contain (10-minute, 30-minute, 1-hour)?  \n",
    "2. Which sensors and nodes are included?  \n",
    "3. What are the start and end timestamps for each file?  \n",
    "4. What is the overall sensing duration across the datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b8ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports needed\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# File paths (relative to repo structure)\n",
    "tenmin_path = \"../data/aggregated/aot_aggregated_10min.csv\"\n",
    "hourly_path = \"../data/aggregated/aot_aggregated_1hour.csv\"\n",
    "nodes_path = \"../data/metadata/nodes.csv\"\n",
    "sensors_path = \"../data/metadata/sensors.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad3cd9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes shape: (126, 9)\n",
      "Sensors shape: (193, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        node_id   project_id  vsn  \\\n",
       " 0  001e0610ba46  AoT_Chicago  004   \n",
       " 1  001e0610ba3b  AoT_Chicago  006   \n",
       " 2  001e0610f02f  AoT_Chicago  00A   \n",
       " 3  001e0610ba8f  AoT_Chicago  00D   \n",
       " 4  001e0610ba16  AoT_Chicago  010   \n",
       " \n",
       "                                        address        lat        lon  \\\n",
       " 0           State St & Jackson Blvd Chicago IL  41.878377 -87.627678   \n",
       " 1           18th St & Lake Shore Dr Chicago IL  41.858136 -87.616055   \n",
       " 2  Lake Shore Drive & Fullerton Ave Chicago IL  41.926261 -87.630758   \n",
       " 3                 Cornell & 47th St Chicago IL  41.810342 -87.590228   \n",
       " 4          Homan Ave & Roosevelt Rd Chicago IL  41.866349 -87.710543   \n",
       " \n",
       "             description      start_timestamp end_timestamp  \n",
       " 0   AoT Chicago (S) [C]  2017/10/09 00:00:00           NaN  \n",
       " 1       AoT Chicago (S)  2017/08/08 00:00:00           NaN  \n",
       " 2  AoT Chicago (S) [CA]  2018/05/07 00:00:00           NaN  \n",
       " 3       AoT Chicago (S)  2017/08/08 00:00:00           NaN  \n",
       " 4   AoT Chicago (S) [C]  2018/07/18 00:00:00           NaN  ,\n",
       "                                      ontology  subsystem           sensor  \\\n",
       " 0               /sensing/air_quality/gases/co  chemsense               co   \n",
       " 1              /sensing/air_quality/gases/h2s  chemsense              h2s   \n",
       " 2              /sensing/air_quality/gases/no2  chemsense              no2   \n",
       " 3               /sensing/air_quality/gases/o3  chemsense               o3   \n",
       " 4  /sensing/air_quality/gases/oxidizing_gases  chemsense  oxidizing_gases   \n",
       " \n",
       "        parameter hrf_unit  hrf_minval  hrf_maxval  \\\n",
       " 0  concentration      ppm         0.0      1000.0   \n",
       " 1  concentration      ppm         0.0        50.0   \n",
       " 2  concentration      ppm         0.0        20.0   \n",
       " 3  concentration      ppm         0.0        20.0   \n",
       " 4  concentration      ppm         0.0       100.0   \n",
       " \n",
       "                                            datasheet  \n",
       " 0  https://github.com/waggle-sensor/sensors/raw/m...  \n",
       " 1  https://github.com/waggle-sensor/sensors/raw/m...  \n",
       " 2  https://github.com/waggle-sensor/sensors/raw/m...  \n",
       " 3  https://github.com/waggle-sensor/sensors/raw/m...  \n",
       " 4  https://github.com/waggle-sensor/sensors/blob/...  )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata\n",
    "nodes = pd.read_csv(nodes_path)\n",
    "sensors = pd.read_csv(sensors_path)\n",
    "\n",
    "print(\"Nodes shape:\", nodes.shape)\n",
    "print(\"Sensors shape:\", sensors.shape)\n",
    "\n",
    "nodes.head(), sensors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56447fb4",
   "metadata": {},
   "source": [
    "> **Note:** Some fields in `nodes.csv` (such as `end_timestamp`) are missing (`NaN`).  \n",
    "> This is expected, as not all nodes had a recorded shutdown when the dataset was exported.  \n",
    "> For consistency and reproducibility, the actual sensing start and end times are derived  \n",
    "> from the aggregated CSV files rather than relying on node metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d68ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10min rows: 58356 columns: ['timestamp', 'node_id', 'sensor', 'parameter', 'value_hrf']\n",
      "1hour rows: 10091 columns: ['timestamp', 'node_id', 'sensor', 'parameter', 'value_hrf']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>node_id</th>\n",
       "      <th>sensor</th>\n",
       "      <th>parameter</th>\n",
       "      <th>value_hrf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-12 00:00:00</td>\n",
       "      <td>001e0610ee36</td>\n",
       "      <td>hih6130</td>\n",
       "      <td>humidity</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-12 00:00:00</td>\n",
       "      <td>001e0610ee36</td>\n",
       "      <td>hih6130</td>\n",
       "      <td>temperature</td>\n",
       "      <td>125.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-12 00:00:00</td>\n",
       "      <td>001e0610ee36</td>\n",
       "      <td>htu21d</td>\n",
       "      <td>humidity</td>\n",
       "      <td>118.99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-12 00:00:00</td>\n",
       "      <td>001e0610ee36</td>\n",
       "      <td>htu21d</td>\n",
       "      <td>temperature</td>\n",
       "      <td>128.86000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-12 00:00:00</td>\n",
       "      <td>001e0610ee43</td>\n",
       "      <td>co</td>\n",
       "      <td>concentration</td>\n",
       "      <td>-0.44551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp       node_id   sensor      parameter  value_hrf\n",
       "0  2020-01-12 00:00:00  001e0610ee36  hih6130       humidity  100.00000\n",
       "1  2020-01-12 00:00:00  001e0610ee36  hih6130    temperature  125.01000\n",
       "2  2020-01-12 00:00:00  001e0610ee36   htu21d       humidity  118.99000\n",
       "3  2020-01-12 00:00:00  001e0610ee36   htu21d    temperature  128.86000\n",
       "4  2020-01-12 00:00:00  001e0610ee43       co  concentration   -0.44551"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load aggregated datasets\n",
    "df_10min = pd.read_csv(tenmin_path)\n",
    "df_hour = pd.read_csv(hourly_path)\n",
    "\n",
    "print(\"10min rows:\", len(df_10min), \"columns:\", df_10min.columns.tolist())\n",
    "print(\"1hour rows:\", len(df_hour), \"columns:\", df_hour.columns.tolist())\n",
    "\n",
    "df_10min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f179a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10min file covers 10 nodes and 6 sensors.\n",
      "1hour file covers 10 nodes and 6 sensors.\n"
     ]
    }
   ],
   "source": [
    "# Unique nodes and sensors in each file\n",
    "nodes_10min = df_10min[\"node_id\"].nunique()\n",
    "sensors_10min = df_10min[\"sensor\"].nunique()\n",
    "\n",
    "nodes_1hour = df_hour[\"node_id\"].nunique()\n",
    "sensors_1hour = df_hour[\"sensor\"].nunique()\n",
    "\n",
    "print(f\"10min file covers {nodes_10min} nodes and {sensors_10min} sensors.\")\n",
    "print(f\"1hour file covers {nodes_1hour} nodes and {sensors_1hour} sensors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae37af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10min dataset time span:\n",
      "Start: 2020-01-12 00:00:00\n",
      "End:   2020-02-08 23:50:00\n",
      "\n",
      "1hour dataset time span:\n",
      "Start: 2020-01-12 00:00:00\n",
      "End:   2020-02-08 23:00:00\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamps to datetime\n",
    "df_10min[\"timestamp\"] = pd.to_datetime(df_10min[\"timestamp\"])\n",
    "df_hour[\"timestamp\"] = pd.to_datetime(df_hour[\"timestamp\"])\n",
    "\n",
    "# Start and end times\n",
    "print(\"10min dataset time span:\")\n",
    "print(\"Start:\", df_10min[\"timestamp\"].min())\n",
    "print(\"End:  \", df_10min[\"timestamp\"].max())\n",
    "\n",
    "print(\"\\n1hour dataset time span:\")\n",
    "print(\"Start:\", df_hour[\"timestamp\"].min())\n",
    "print(\"End:  \", df_hour[\"timestamp\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61b8d2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10min dataset duration: 27 days\n",
      "1hour dataset duration: 27 days\n"
     ]
    }
   ],
   "source": [
    "# Calculate duration in days\n",
    "duration_10min = (df_10min[\"timestamp\"].max() - df_10min[\"timestamp\"].min()).days\n",
    "duration_1hour = (df_hour[\"timestamp\"].max() - df_hour[\"timestamp\"].min()).days\n",
    "\n",
    "print(f\"10min dataset duration: {duration_10min} days\")\n",
    "print(f\"1hour dataset duration: {duration_1hour} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b48fa",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| File                     | Nodes | Sensors | Start Date | End Date   | Duration (days) |\n",
    "|--------------------------|-------|---------|------------|------------|-----------------|\n",
    "| aot_aggregated_10min.csv | 10    | 6       | 2020-01-12 | 2020-02-08 | 27              |\n",
    "| aot_aggregated_1hour.csv | 10    | 6       | 2020-01-12 | 2020-02-08 | 27              |\n",
    "\n",
    "> Both the 10-minute and 1-hour datasets cover 10 nodes and 6 sensors  \n",
    "> over the same time span (Jan 12 – Feb 8, 2020), lasting 27 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85670c",
   "metadata": {},
   "source": [
    "> ⚠️ **Note on dataset scope**  \n",
    "> The research presented in the associated paper was conducted on the **full AoT dataset**  \n",
    "> (≈500 deployed nodes across Chicago, with raw data collected at 30-second intervals).  \n",
    ">  \n",
    "> For reproducibility in this repository, we provide a **subset** covering 10 nodes,  \n",
    "> 6 sensors, and a continuous 27-day window (Jan 12 – Feb 8, 2020).  \n",
    ">  \n",
    "> This subset is included to demonstrate the workflows and code without requiring  \n",
    "> access to the full dataset. The same methods apply directly to the full-scale data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
